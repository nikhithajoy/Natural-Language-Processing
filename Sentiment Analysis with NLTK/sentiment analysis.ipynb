{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by tokenizing, converting to lowercase,\n",
    "    and removing stopwords.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of preprocessed tokens.\n",
    "    \"\"\"\n",
    "    # Tokenize the text and filter out non-alphabetic words\n",
    "    tokens = [word.lower() for word in word_tokenize(text) if word.isalpha()]\n",
    "\n",
    "    # Get a set of English stopwords and filter out stopwords from tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of the input text using NLTK's SentimentIntensityAnalyzer.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to analyze.\n",
    "\n",
    "    Returns:\n",
    "        float: The sentiment score (compound) of the text.\n",
    "    \"\"\"\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = sia.polarity_scores(text)['compound']\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for sentiment analysis\n",
    "text1 = \"I love this product! It's amazing.\"\n",
    "text2 = \"This movie is so boring and terrible.\"\n",
    "text3 = \"The weather today is neither good nor bad.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text and analyze sentiment\n",
    "tokens1 = preprocess_text(text1)\n",
    "tokens2 = preprocess_text(text2)\n",
    "tokens3 = preprocess_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score1 = analyze_sentiment(text1)\n",
    "sentiment_score2 = analyze_sentiment(text2)\n",
    "sentiment_score3 = analyze_sentiment(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Score for Text 1: 0.8516\n",
      "Sentiment Score for Text 2: -0.7472\n",
      "Sentiment Score for Text 3: -0.5824\n"
     ]
    }
   ],
   "source": [
    "# Display sentiment scores\n",
    "print(f\"Sentiment Score for Text 1: {sentiment_score1}\")\n",
    "print(f\"Sentiment Score for Text 2: {sentiment_score2}\")\n",
    "print(f\"Sentiment Score for Text 3: {sentiment_score3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these sentiment scores:\n",
    "\n",
    "Text 1 is clearly positive.\n",
    "\n",
    "Text 2 is strongly negative.\n",
    "\n",
    "Text 3 leans towards a negative sentiment, but it's less negative compared to Text 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
